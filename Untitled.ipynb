{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397391cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification, pipeline\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "\n",
    "emotion = pipeline('sentiment-analysis', model='arpanghoshal/EmoRoBERTa')\n",
    "\n",
    "emotion_labels = emotion(\"As the shadows deepened around me, an eerie silence hung in the air, broken only by the haunting whispers that seemed to echo from the darkness, sending shivers down my spine. The unknown gripped my heart with a paralyzing fear, leaving me unable to move, trapped in a web of unsettling uncertainty.\")\n",
    "print(emotion_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca2ccfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'fear', 'score': 0.9877979159355164}]\n"
     ]
    }
   ],
   "source": [
    "emotion_labels = emotion(\"As the shadows deepened around me, an eerie silence hung in the air, broken only by the haunting whispers that seemed to echo from the darkness, sending shivers down my spine. The unknown gripped my heart with a paralyzing fear, leaving me unable to move, trapped in a web of unsettling uncertainty.\")\n",
    "print(emotion_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5560df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "def get_emotion(text):\n",
    "    return emotion(text)[0]['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "295a6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6018cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...classifier\n",
      "......vars\n",
      "...classifier\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...classifier\\dropout\n",
      "......vars\n",
      "...classifier\\out_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\embeddings\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\tf_roberta_main_layer\\embeddings\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\embeddings\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_10\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_11\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_1\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_2\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_3\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_4\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_5\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_6\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_7\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_8\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\dense_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\dense_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\dense_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\dense_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\self_attention\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\self_attention\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\self_attention\\key\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\self_attention\\query\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\attention\\self_attention\\value\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\bert_output\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\bert_output\\LayerNorm\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\bert_output\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\bert_output\\dropout\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\intermediate\n",
      "......vars\n",
      "...layers\\tf_roberta_main_layer\\encoder\\layer\\tf_roberta_layer_9\\intermediate\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-26 01:49:55         2969\n",
      "metadata.json                                  2023-12-26 01:49:55           64\n",
      "variables.h5                                   2023-12-26 01:49:59    499173920\n"
     ]
    }
   ],
   "source": [
    "with open('sentiment_analysis_model.pkl',\"wb\") as f:\n",
    "    pickle.dump((tokenizer,model),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "163b5b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_roberta_for_sequence_classification' (type TFRobertaForSequenceClassification).\n\nData of type <class 'torch.Tensor'> is not allowed only (<class 'tensorflow.python.framework.ops.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>, <class 'keras.engine.keras_tensor.KerasTensor'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_roberta_for_sequence_classification' (type TFRobertaForSequenceClassification):\n  • input_ids=tensor([[    0, 30086,   961,     2]])\n  • attention_mask=tensor([[1, 1, 1, 1]])\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • labels=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi everyone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text,return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mlogits)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py:441\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m--> 441\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py:518\u001b[0m, in \u001b[0;36minput_processing\u001b[1;34m(func, config, **kwargs)\u001b[0m\n\u001b[0;32m    516\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_roberta_for_sequence_classification' (type TFRobertaForSequenceClassification).\n\nData of type <class 'torch.Tensor'> is not allowed only (<class 'tensorflow.python.framework.ops.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>, <class 'keras.engine.keras_tensor.KerasTensor'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_roberta_for_sequence_classification' (type TFRobertaForSequenceClassification):\n  • input_ids=tensor([[    0, 30086,   961,     2]])\n  • attention_mask=tensor([[1, 1, 1, 1]])\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • labels=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "text = \"Hi everyone\"\n",
    "inputs = tokenizer(text,return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b70e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
